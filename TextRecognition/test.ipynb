{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocr.tools.config import Cfg\n",
    "from ocr.model.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "config = Cfg.load_config_from_name('vgg_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_params = {\n",
    "    'name':'hw',\n",
    "    'data_root':'../../train_data/ocr_recognition/',\n",
    "    'train_annotation':'train_line_annotation.txt',\n",
    "    'valid_annotation':'test_line_annotation.txt'\n",
    "}\n",
    "\n",
    "params = {\n",
    "         'print_every':200,\n",
    "         'valid_every':15*200,\n",
    "          'iters':20000,\n",
    "          'checkpoint':'./checkpoint/transformerocr_checkpoint.pth',    \n",
    "          'export':'./weights/transformerocr.pth',\n",
    "          'metrics': 10000\n",
    "         }\n",
    "\n",
    "config['trainer'].update(params)\n",
    "config['dataset'].update(dataset_params)\n",
    "config['device'] = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 4, 'A': 5, 'à': 6, 'À': 7, 'ả': 8, 'Ả': 9, 'ã': 10, 'Ã': 11, 'á': 12, 'Á': 13, 'ạ': 14, 'Ạ': 15, 'ă': 16, 'Ă': 17, 'ằ': 18, 'Ằ': 19, 'ẳ': 20, 'Ẳ': 21, 'ẵ': 22, 'Ẵ': 23, 'ắ': 24, 'Ắ': 25, 'ặ': 26, 'Ặ': 27, 'â': 28, 'Â': 29, 'ầ': 30, 'Ầ': 31, 'ẩ': 32, 'Ẩ': 33, 'ẫ': 34, 'Ẫ': 35, 'ấ': 36, 'Ấ': 37, 'ậ': 38, 'Ậ': 39, 'b': 40, 'B': 41, 'c': 42, 'C': 43, 'd': 44, 'D': 45, 'đ': 46, 'Đ': 47, 'e': 48, 'E': 49, 'è': 50, 'È': 51, 'ẻ': 52, 'Ẻ': 53, 'ẽ': 54, 'Ẽ': 55, 'é': 56, 'É': 57, 'ẹ': 58, 'Ẹ': 59, 'ê': 60, 'Ê': 61, 'ề': 62, 'Ề': 63, 'ể': 64, 'Ể': 65, 'ễ': 66, 'Ễ': 67, 'ế': 68, 'Ế': 69, 'ệ': 70, 'Ệ': 71, 'f': 72, 'F': 73, 'g': 74, 'G': 75, 'h': 76, 'H': 77, 'i': 78, 'I': 79, 'ì': 80, 'Ì': 81, 'ỉ': 82, 'Ỉ': 83, 'ĩ': 84, 'Ĩ': 85, 'í': 86, 'Í': 87, 'ị': 88, 'Ị': 89, 'j': 90, 'J': 91, 'k': 92, 'K': 93, 'l': 94, 'L': 95, 'm': 96, 'M': 97, 'n': 98, 'N': 99, 'o': 100, 'O': 101, 'ò': 102, 'Ò': 103, 'ỏ': 104, 'Ỏ': 105, 'õ': 106, 'Õ': 107, 'ó': 108, 'Ó': 109, 'ọ': 110, 'Ọ': 111, 'ô': 112, 'Ô': 113, 'ồ': 114, 'Ồ': 115, 'ổ': 116, 'Ổ': 117, 'ỗ': 118, 'Ỗ': 119, 'ố': 120, 'Ố': 121, 'ộ': 122, 'Ộ': 123, 'ơ': 124, 'Ơ': 125, 'ờ': 126, 'Ờ': 127, 'ở': 128, 'Ở': 129, 'ỡ': 130, 'Ỡ': 131, 'ớ': 132, 'Ớ': 133, 'ợ': 134, 'Ợ': 135, 'p': 136, 'P': 137, 'q': 138, 'Q': 139, 'r': 140, 'R': 141, 's': 142, 'S': 143, 't': 144, 'T': 145, 'u': 146, 'U': 147, 'ù': 148, 'Ù': 149, 'ủ': 150, 'Ủ': 151, 'ũ': 152, 'Ũ': 153, 'ú': 154, 'Ú': 155, 'ụ': 156, 'Ụ': 157, 'ư': 158, 'Ư': 159, 'ừ': 160, 'Ừ': 161, 'ử': 162, 'Ử': 163, 'ữ': 164, 'Ữ': 165, 'ứ': 166, 'Ứ': 167, 'ự': 168, 'Ự': 169, 'v': 170, 'V': 171, 'w': 172, 'W': 173, 'x': 174, 'X': 175, 'y': 176, 'Y': 177, 'ỳ': 178, 'Ỳ': 179, 'ỷ': 180, 'Ỷ': 181, 'ỹ': 182, 'Ỹ': 183, 'ý': 184, 'Ý': 185, 'ỵ': 186, 'Ỵ': 187, 'z': 188, 'Z': 189, '0': 190, '1': 191, '2': 192, '3': 193, '4': 194, '5': 195, '6': 196, '7': 197, '8': 198, '9': 199, '!': 200, '\"': 201, '#': 202, '$': 203, '%': 204, '&': 205, \"'\": 206, '(': 207, ')': 208, '*': 209, '+': 210, ',': 211, '-': 212, '.': 213, '/': 214, ':': 215, ';': 216, '<': 217, '=': 218, '>': 219, '?': 220, '@': 221, '[': 222, '\\\\': 223, ']': 224, '^': 225, '_': 226, '`': 227, '{': 228, '|': 229, '}': 230, '~': 231, '²': 232, '“': 233, '−': 234, '”': 235, ' ': 236}\n",
      "{4: 'a', 5: 'A', 6: 'à', 7: 'À', 8: 'ả', 9: 'Ả', 10: 'ã', 11: 'Ã', 12: 'á', 13: 'Á', 14: 'ạ', 15: 'Ạ', 16: 'ă', 17: 'Ă', 18: 'ằ', 19: 'Ằ', 20: 'ẳ', 21: 'Ẳ', 22: 'ẵ', 23: 'Ẵ', 24: 'ắ', 25: 'Ắ', 26: 'ặ', 27: 'Ặ', 28: 'â', 29: 'Â', 30: 'ầ', 31: 'Ầ', 32: 'ẩ', 33: 'Ẩ', 34: 'ẫ', 35: 'Ẫ', 36: 'ấ', 37: 'Ấ', 38: 'ậ', 39: 'Ậ', 40: 'b', 41: 'B', 42: 'c', 43: 'C', 44: 'd', 45: 'D', 46: 'đ', 47: 'Đ', 48: 'e', 49: 'E', 50: 'è', 51: 'È', 52: 'ẻ', 53: 'Ẻ', 54: 'ẽ', 55: 'Ẽ', 56: 'é', 57: 'É', 58: 'ẹ', 59: 'Ẹ', 60: 'ê', 61: 'Ê', 62: 'ề', 63: 'Ề', 64: 'ể', 65: 'Ể', 66: 'ễ', 67: 'Ễ', 68: 'ế', 69: 'Ế', 70: 'ệ', 71: 'Ệ', 72: 'f', 73: 'F', 74: 'g', 75: 'G', 76: 'h', 77: 'H', 78: 'i', 79: 'I', 80: 'ì', 81: 'Ì', 82: 'ỉ', 83: 'Ỉ', 84: 'ĩ', 85: 'Ĩ', 86: 'í', 87: 'Í', 88: 'ị', 89: 'Ị', 90: 'j', 91: 'J', 92: 'k', 93: 'K', 94: 'l', 95: 'L', 96: 'm', 97: 'M', 98: 'n', 99: 'N', 100: 'o', 101: 'O', 102: 'ò', 103: 'Ò', 104: 'ỏ', 105: 'Ỏ', 106: 'õ', 107: 'Õ', 108: 'ó', 109: 'Ó', 110: 'ọ', 111: 'Ọ', 112: 'ô', 113: 'Ô', 114: 'ồ', 115: 'Ồ', 116: 'ổ', 117: 'Ổ', 118: 'ỗ', 119: 'Ỗ', 120: 'ố', 121: 'Ố', 122: 'ộ', 123: 'Ộ', 124: 'ơ', 125: 'Ơ', 126: 'ờ', 127: 'Ờ', 128: 'ở', 129: 'Ở', 130: 'ỡ', 131: 'Ỡ', 132: 'ớ', 133: 'Ớ', 134: 'ợ', 135: 'Ợ', 136: 'p', 137: 'P', 138: 'q', 139: 'Q', 140: 'r', 141: 'R', 142: 's', 143: 'S', 144: 't', 145: 'T', 146: 'u', 147: 'U', 148: 'ù', 149: 'Ù', 150: 'ủ', 151: 'Ủ', 152: 'ũ', 153: 'Ũ', 154: 'ú', 155: 'Ú', 156: 'ụ', 157: 'Ụ', 158: 'ư', 159: 'Ư', 160: 'ừ', 161: 'Ừ', 162: 'ử', 163: 'Ử', 164: 'ữ', 165: 'Ữ', 166: 'ứ', 167: 'Ứ', 168: 'ự', 169: 'Ự', 170: 'v', 171: 'V', 172: 'w', 173: 'W', 174: 'x', 175: 'X', 176: 'y', 177: 'Y', 178: 'ỳ', 179: 'Ỳ', 180: 'ỷ', 181: 'Ỷ', 182: 'ỹ', 183: 'Ỹ', 184: 'ý', 185: 'Ý', 186: 'ỵ', 187: 'Ỵ', 188: 'z', 189: 'Z', 190: '0', 191: '1', 192: '2', 193: '3', 194: '4', 195: '5', 196: '6', 197: '7', 198: '8', 199: '9', 200: '!', 201: '\"', 202: '#', 203: '$', 204: '%', 205: '&', 206: \"'\", 207: '(', 208: ')', 209: '*', 210: '+', 211: ',', 212: '-', 213: '.', 214: '/', 215: ':', 216: ';', 217: '<', 218: '=', 219: '>', 220: '?', 221: '@', 222: '[', 223: '\\\\', 224: ']', 225: '^', 226: '_', 227: '`', 228: '{', 229: '|', 230: '}', 231: '~', 232: '²', 233: '“', 234: '−', 235: '”', 236: ' '}\n",
      "Model weight /tmp/vgg_transformer.pth exsits. Ignore download!\n",
      "/tmp/vgg_transformer.pth\n",
      "cnn.model.features.0.weight not found\n",
      "cnn.model.features.0.bias not found\n",
      "cnn.model.features.1.weight not found\n",
      "cnn.model.features.1.bias not found\n",
      "cnn.model.features.3.weight not found\n",
      "cnn.model.features.3.bias not found\n",
      "cnn.model.features.4.weight not found\n",
      "cnn.model.features.4.bias not found\n",
      "cnn.model.features.7.weight not found\n",
      "cnn.model.features.7.bias not found\n",
      "cnn.model.features.8.weight not found\n",
      "cnn.model.features.8.bias not found\n",
      "cnn.model.features.10.weight not found\n",
      "cnn.model.features.10.bias not found\n",
      "cnn.model.features.11.weight not found\n",
      "cnn.model.features.11.bias not found\n",
      "cnn.model.features.14.weight not found\n",
      "cnn.model.features.14.bias not found\n",
      "cnn.model.features.15.weight not found\n",
      "cnn.model.features.15.bias not found\n",
      "cnn.model.features.17.weight not found\n",
      "cnn.model.features.17.bias not found\n",
      "cnn.model.features.18.weight not found\n",
      "cnn.model.features.18.bias not found\n",
      "cnn.model.features.20.weight not found\n",
      "cnn.model.features.20.bias not found\n",
      "cnn.model.features.21.weight not found\n",
      "cnn.model.features.21.bias not found\n",
      "cnn.model.features.23.weight not found\n",
      "cnn.model.features.23.bias not found\n",
      "cnn.model.features.24.weight not found\n",
      "cnn.model.features.24.bias not found\n",
      "cnn.model.features.27.weight not found\n",
      "cnn.model.features.27.bias not found\n",
      "cnn.model.features.28.weight not found\n",
      "cnn.model.features.28.bias not found\n",
      "cnn.model.features.30.weight not found\n",
      "cnn.model.features.30.bias not found\n",
      "cnn.model.features.31.weight not found\n",
      "cnn.model.features.31.bias not found\n",
      "cnn.model.features.33.weight not found\n",
      "cnn.model.features.33.bias not found\n",
      "cnn.model.features.34.weight not found\n",
      "cnn.model.features.34.bias not found\n",
      "cnn.model.features.36.weight not found\n",
      "cnn.model.features.36.bias not found\n",
      "cnn.model.features.37.weight not found\n",
      "cnn.model.features.37.bias not found\n",
      "cnn.model.features.40.weight not found\n",
      "cnn.model.features.40.bias not found\n",
      "cnn.model.features.41.weight not found\n",
      "cnn.model.features.41.bias not found\n",
      "cnn.model.features.43.weight not found\n",
      "cnn.model.features.43.bias not found\n",
      "cnn.model.features.44.weight not found\n",
      "cnn.model.features.44.bias not found\n",
      "cnn.model.features.46.weight not found\n",
      "cnn.model.features.46.bias not found\n",
      "cnn.model.features.47.weight not found\n",
      "cnn.model.features.47.bias not found\n",
      "cnn.model.features.49.weight not found\n",
      "cnn.model.features.49.bias not found\n",
      "cnn.model.features.50.weight not found\n",
      "cnn.model.features.50.bias not found\n",
      "cnn.model.last_conv1x1.weight not found\n",
      "cnn.model.last_conv1x1.bias not found\n",
      "transformer.embed_tgt.weight not found\n",
      "transformer.transformer.encoder.layers.0.self_attn.in_proj_weight not found\n",
      "transformer.transformer.encoder.layers.0.self_attn.in_proj_bias not found\n",
      "transformer.transformer.encoder.layers.0.self_attn.out_proj.weight not found\n",
      "transformer.transformer.encoder.layers.0.self_attn.out_proj.bias not found\n",
      "transformer.transformer.encoder.layers.0.linear1.weight not found\n",
      "transformer.transformer.encoder.layers.0.linear1.bias not found\n",
      "transformer.transformer.encoder.layers.0.linear2.weight not found\n",
      "transformer.transformer.encoder.layers.0.linear2.bias not found\n",
      "transformer.transformer.encoder.layers.0.norm1.weight not found\n",
      "transformer.transformer.encoder.layers.0.norm1.bias not found\n",
      "transformer.transformer.encoder.layers.0.norm2.weight not found\n",
      "transformer.transformer.encoder.layers.0.norm2.bias not found\n",
      "transformer.transformer.encoder.layers.1.self_attn.in_proj_weight not found\n",
      "transformer.transformer.encoder.layers.1.self_attn.in_proj_bias not found\n",
      "transformer.transformer.encoder.layers.1.self_attn.out_proj.weight not found\n",
      "transformer.transformer.encoder.layers.1.self_attn.out_proj.bias not found\n",
      "transformer.transformer.encoder.layers.1.linear1.weight not found\n",
      "transformer.transformer.encoder.layers.1.linear1.bias not found\n",
      "transformer.transformer.encoder.layers.1.linear2.weight not found\n",
      "transformer.transformer.encoder.layers.1.linear2.bias not found\n",
      "transformer.transformer.encoder.layers.1.norm1.weight not found\n",
      "transformer.transformer.encoder.layers.1.norm1.bias not found\n",
      "transformer.transformer.encoder.layers.1.norm2.weight not found\n",
      "transformer.transformer.encoder.layers.1.norm2.bias not found\n",
      "transformer.transformer.encoder.layers.2.self_attn.in_proj_weight not found\n",
      "transformer.transformer.encoder.layers.2.self_attn.in_proj_bias not found\n",
      "transformer.transformer.encoder.layers.2.self_attn.out_proj.weight not found\n",
      "transformer.transformer.encoder.layers.2.self_attn.out_proj.bias not found\n",
      "transformer.transformer.encoder.layers.2.linear1.weight not found\n",
      "transformer.transformer.encoder.layers.2.linear1.bias not found\n",
      "transformer.transformer.encoder.layers.2.linear2.weight not found\n",
      "transformer.transformer.encoder.layers.2.linear2.bias not found\n",
      "transformer.transformer.encoder.layers.2.norm1.weight not found\n",
      "transformer.transformer.encoder.layers.2.norm1.bias not found\n",
      "transformer.transformer.encoder.layers.2.norm2.weight not found\n",
      "transformer.transformer.encoder.layers.2.norm2.bias not found\n",
      "transformer.transformer.encoder.layers.3.self_attn.in_proj_weight not found\n",
      "transformer.transformer.encoder.layers.3.self_attn.in_proj_bias not found\n",
      "transformer.transformer.encoder.layers.3.self_attn.out_proj.weight not found\n",
      "transformer.transformer.encoder.layers.3.self_attn.out_proj.bias not found\n",
      "transformer.transformer.encoder.layers.3.linear1.weight not found\n",
      "transformer.transformer.encoder.layers.3.linear1.bias not found\n",
      "transformer.transformer.encoder.layers.3.linear2.weight not found\n",
      "transformer.transformer.encoder.layers.3.linear2.bias not found\n",
      "transformer.transformer.encoder.layers.3.norm1.weight not found\n",
      "transformer.transformer.encoder.layers.3.norm1.bias not found\n",
      "transformer.transformer.encoder.layers.3.norm2.weight not found\n",
      "transformer.transformer.encoder.layers.3.norm2.bias not found\n",
      "transformer.transformer.encoder.layers.4.self_attn.in_proj_weight not found\n",
      "transformer.transformer.encoder.layers.4.self_attn.in_proj_bias not found\n",
      "transformer.transformer.encoder.layers.4.self_attn.out_proj.weight not found\n",
      "transformer.transformer.encoder.layers.4.self_attn.out_proj.bias not found\n",
      "transformer.transformer.encoder.layers.4.linear1.weight not found\n",
      "transformer.transformer.encoder.layers.4.linear1.bias not found\n",
      "transformer.transformer.encoder.layers.4.linear2.weight not found\n",
      "transformer.transformer.encoder.layers.4.linear2.bias not found\n",
      "transformer.transformer.encoder.layers.4.norm1.weight not found\n",
      "transformer.transformer.encoder.layers.4.norm1.bias not found\n",
      "transformer.transformer.encoder.layers.4.norm2.weight not found\n",
      "transformer.transformer.encoder.layers.4.norm2.bias not found\n",
      "transformer.transformer.encoder.layers.5.self_attn.in_proj_weight not found\n",
      "transformer.transformer.encoder.layers.5.self_attn.in_proj_bias not found\n",
      "transformer.transformer.encoder.layers.5.self_attn.out_proj.weight not found\n",
      "transformer.transformer.encoder.layers.5.self_attn.out_proj.bias not found\n",
      "transformer.transformer.encoder.layers.5.linear1.weight not found\n",
      "transformer.transformer.encoder.layers.5.linear1.bias not found\n",
      "transformer.transformer.encoder.layers.5.linear2.weight not found\n",
      "transformer.transformer.encoder.layers.5.linear2.bias not found\n",
      "transformer.transformer.encoder.layers.5.norm1.weight not found\n",
      "transformer.transformer.encoder.layers.5.norm1.bias not found\n",
      "transformer.transformer.encoder.layers.5.norm2.weight not found\n",
      "transformer.transformer.encoder.layers.5.norm2.bias not found\n",
      "transformer.transformer.encoder.norm.weight not found\n",
      "transformer.transformer.encoder.norm.bias not found\n",
      "transformer.transformer.decoder.layers.0.self_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.0.self_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.0.self_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.0.self_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.0.multihead_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.0.multihead_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.0.multihead_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.0.multihead_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.0.linear1.weight not found\n",
      "transformer.transformer.decoder.layers.0.linear1.bias not found\n",
      "transformer.transformer.decoder.layers.0.linear2.weight not found\n",
      "transformer.transformer.decoder.layers.0.linear2.bias not found\n",
      "transformer.transformer.decoder.layers.0.norm1.weight not found\n",
      "transformer.transformer.decoder.layers.0.norm1.bias not found\n",
      "transformer.transformer.decoder.layers.0.norm2.weight not found\n",
      "transformer.transformer.decoder.layers.0.norm2.bias not found\n",
      "transformer.transformer.decoder.layers.0.norm3.weight not found\n",
      "transformer.transformer.decoder.layers.0.norm3.bias not found\n",
      "transformer.transformer.decoder.layers.1.self_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.1.self_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.1.self_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.1.self_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.1.multihead_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.1.multihead_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.1.multihead_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.1.multihead_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.1.linear1.weight not found\n",
      "transformer.transformer.decoder.layers.1.linear1.bias not found\n",
      "transformer.transformer.decoder.layers.1.linear2.weight not found\n",
      "transformer.transformer.decoder.layers.1.linear2.bias not found\n",
      "transformer.transformer.decoder.layers.1.norm1.weight not found\n",
      "transformer.transformer.decoder.layers.1.norm1.bias not found\n",
      "transformer.transformer.decoder.layers.1.norm2.weight not found\n",
      "transformer.transformer.decoder.layers.1.norm2.bias not found\n",
      "transformer.transformer.decoder.layers.1.norm3.weight not found\n",
      "transformer.transformer.decoder.layers.1.norm3.bias not found\n",
      "transformer.transformer.decoder.layers.2.self_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.2.self_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.2.self_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.2.self_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.2.multihead_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.2.multihead_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.2.multihead_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.2.multihead_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.2.linear1.weight not found\n",
      "transformer.transformer.decoder.layers.2.linear1.bias not found\n",
      "transformer.transformer.decoder.layers.2.linear2.weight not found\n",
      "transformer.transformer.decoder.layers.2.linear2.bias not found\n",
      "transformer.transformer.decoder.layers.2.norm1.weight not found\n",
      "transformer.transformer.decoder.layers.2.norm1.bias not found\n",
      "transformer.transformer.decoder.layers.2.norm2.weight not found\n",
      "transformer.transformer.decoder.layers.2.norm2.bias not found\n",
      "transformer.transformer.decoder.layers.2.norm3.weight not found\n",
      "transformer.transformer.decoder.layers.2.norm3.bias not found\n",
      "transformer.transformer.decoder.layers.3.self_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.3.self_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.3.self_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.3.self_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.3.multihead_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.3.multihead_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.3.multihead_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.3.multihead_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.3.linear1.weight not found\n",
      "transformer.transformer.decoder.layers.3.linear1.bias not found\n",
      "transformer.transformer.decoder.layers.3.linear2.weight not found\n",
      "transformer.transformer.decoder.layers.3.linear2.bias not found\n",
      "transformer.transformer.decoder.layers.3.norm1.weight not found\n",
      "transformer.transformer.decoder.layers.3.norm1.bias not found\n",
      "transformer.transformer.decoder.layers.3.norm2.weight not found\n",
      "transformer.transformer.decoder.layers.3.norm2.bias not found\n",
      "transformer.transformer.decoder.layers.3.norm3.weight not found\n",
      "transformer.transformer.decoder.layers.3.norm3.bias not found\n",
      "transformer.transformer.decoder.layers.4.self_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.4.self_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.4.self_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.4.self_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.4.multihead_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.4.multihead_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.4.multihead_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.4.multihead_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.4.linear1.weight not found\n",
      "transformer.transformer.decoder.layers.4.linear1.bias not found\n",
      "transformer.transformer.decoder.layers.4.linear2.weight not found\n",
      "transformer.transformer.decoder.layers.4.linear2.bias not found\n",
      "transformer.transformer.decoder.layers.4.norm1.weight not found\n",
      "transformer.transformer.decoder.layers.4.norm1.bias not found\n",
      "transformer.transformer.decoder.layers.4.norm2.weight not found\n",
      "transformer.transformer.decoder.layers.4.norm2.bias not found\n",
      "transformer.transformer.decoder.layers.4.norm3.weight not found\n",
      "transformer.transformer.decoder.layers.4.norm3.bias not found\n",
      "transformer.transformer.decoder.layers.5.self_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.5.self_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.5.self_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.5.self_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.5.multihead_attn.in_proj_weight not found\n",
      "transformer.transformer.decoder.layers.5.multihead_attn.in_proj_bias not found\n",
      "transformer.transformer.decoder.layers.5.multihead_attn.out_proj.weight not found\n",
      "transformer.transformer.decoder.layers.5.multihead_attn.out_proj.bias not found\n",
      "transformer.transformer.decoder.layers.5.linear1.weight not found\n",
      "transformer.transformer.decoder.layers.5.linear1.bias not found\n",
      "transformer.transformer.decoder.layers.5.linear2.weight not found\n",
      "transformer.transformer.decoder.layers.5.linear2.bias not found\n",
      "transformer.transformer.decoder.layers.5.norm1.weight not found\n",
      "transformer.transformer.decoder.layers.5.norm1.bias not found\n",
      "transformer.transformer.decoder.layers.5.norm2.weight not found\n",
      "transformer.transformer.decoder.layers.5.norm2.bias not found\n",
      "transformer.transformer.decoder.layers.5.norm3.weight not found\n",
      "transformer.transformer.decoder.layers.5.norm3.bias not found\n",
      "transformer.transformer.decoder.norm.weight not found\n",
      "transformer.transformer.decoder.norm.bias not found\n",
      "transformer.fc.weight not found\n",
      "transformer.fc.bias not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Create train_hw:   9%|███▍                                   | 8011/89999 [00:02<00:30, 2719.43it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(config, pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Github/Vietnamese-OCR/TextRecognition/ocr/model/train.py:79\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, config, pretrained, augmentor)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_aug:\n\u001b[1;32m     77\u001b[0m     transforms \u001b[39m=\u001b[39m  augmentor\n\u001b[0;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_gen(\u001b[39m'\u001b[39;49m\u001b[39mtrain_\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_name), \n\u001b[1;32m     80\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_root, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_annotation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmasked_language_model, transform\u001b[39m=\u001b[39;49mtransforms)\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_annotation:\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_gen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_gen(\u001b[39m'\u001b[39m\u001b[39mvalid_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name), \n\u001b[1;32m     83\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_annotation, masked_language_model\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Github/Vietnamese-OCR/TextRecognition/ocr/model/train.py:311\u001b[0m, in \u001b[0;36mTrainer.data_gen\u001b[0;34m(self, lmdb_path, data_root, annotation, masked_language_model, transform)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_gen\u001b[39m(\u001b[39mself\u001b[39m, lmdb_path, data_root, annotation, masked_language_model\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 311\u001b[0m     dataset \u001b[39m=\u001b[39m OCRDataset(lmdb_path\u001b[39m=\u001b[39;49mlmdb_path, \n\u001b[1;32m    312\u001b[0m             root_dir\u001b[39m=\u001b[39;49mdata_root, annotation_path\u001b[39m=\u001b[39;49mannotation, \n\u001b[1;32m    313\u001b[0m             vocab\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab, transform\u001b[39m=\u001b[39;49mtransform, \n\u001b[1;32m    314\u001b[0m             image_height\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mimage_height\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    315\u001b[0m             image_min_width\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mimage_min_width\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    316\u001b[0m             image_max_width\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mimage_max_width\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    318\u001b[0m     sampler \u001b[39m=\u001b[39m ClusterRandomSampler(dataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m     collate_fn \u001b[39m=\u001b[39m Collator(masked_language_model)\n",
      "File \u001b[0;32m~/Github/Vietnamese-OCR/TextRecognition/ocr/loader/dataloader.py:46\u001b[0m, in \u001b[0;36mOCRDataset.__init__\u001b[0;34m(self, lmdb_path, root_dir, annotation_path, vocab, image_height, image_min_width, image_max_width, transform)\u001b[0m\n\u001b[1;32m     44\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush() \u001b[39m# Used to flush the output buffer associated with the standard output stream.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     createDataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlmdb_path, root_dir, annotation_path)\n\u001b[1;32m     48\u001b[0m \u001b[39m# Open envrioment\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39m=\u001b[39m lmdb\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlmdb_path, max_readers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,\n\u001b[1;32m     50\u001b[0m                      readonly\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lock\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, readahead\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, meminit\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Github/Vietnamese-OCR/TextRecognition/ocr/tools/create_dataset.py:73\u001b[0m, in \u001b[0;36mcreateDataset\u001b[0;34m(output_path, root_dir, annotation_path)\u001b[0m\n\u001b[1;32m     70\u001b[0m process_bar \u001b[39m=\u001b[39m tqdm(\u001b[39mrange\u001b[39m(n_samples), ncols\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCreate \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(output_path))\n\u001b[1;32m     71\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m process_bar:\n\u001b[1;32m     72\u001b[0m     \u001b[39m#Get name and label of image file\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     image_file, label \u001b[39m=\u001b[39m annotations[i]\n\u001b[1;32m     74\u001b[0m     \u001b[39m# Get image path\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     image_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root_dir, image_file)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config, pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
